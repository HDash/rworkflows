if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
}
func(x)
}
db[,lapply(.SD,get_gh), .SDcols = cols]
db[,lapply(.SD,get_gh), .SDcols = cols]
db[,sapply(git_url,get_gh)]
db[,lapply(git_url,get_gh)]
db[,lapply(git_url,URL)]
db[,lapply(URK,get_gh)]
db[,lapply(URL,get_gh)]
get_gh <- function(col){
x <- strsplit(col, ",")
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
}
db[,lapply(git_url,get_gh)]
db[,lapply(URL,get_gh)]
db[,sapply(URL,get_gh)]
db[,sapply(git_url,get_gh)]
db[,sapply(URL,get_gh)]
data.table::nafill(list(db[,sapply(git_url,get_gh)]
db[,sapply(URL,get_gh)]))
data.table::nafill(list(db[,sapply(git_url,get_gh)],
db[,sapply(URL,get_gh)]))
db[,list(tmp1=sapply(git_url,get_gh))],
db[,list(tmp1=sapply(git_url,get_gh))]
db[,list(sapply(git_url,get_gh),
sapply(git_url,get_gh))]
db[,list(sapply(git_url,get_gh),
sapply(git_url,URL),
sapply(git_url,BugReports))]
db[,list(sapply(git_url,get_gh),
sapply(URL,get_gh),
sapply(BugReports,get_gh))]
db[,list(sapply(git_url,get_gh),
sapply(URL,get_gh),
sapply(BugReports,get_gh))] |>
data.table::nafill()
db[,list(sapply(git_url,get_gh),
sapply(URL,get_gh),
sapply(BugReports,get_gh))] |>
data.table::fcoalesce()
db$url_github <- db[,list(sapply(git_url,get_gh),
sapply(URL,get_gh),
sapply(BugReports,get_gh))] |>
data.table::fcoalesce()
db[,list(sapply(.DS,get_gh)),.SDcols = cols]
db[,list(sapply(.SD,get_gh)),.SDcols = cols]
db[,list(lapply(.SD,get_gh)),]
db[,list(lapply(.SD,get_gh)),.SDcols = cols]
db[,list(lapply(.SD,get_gh,-1)),.SDcols = cols]
db[,(cols) :=lapply(.SD,get_gh),.SDcols = cols]
db
db[,(cols) :=lapply(.SD,get_gh),.SDcols = cols, by=.I]
db$r_repo
db$Package
db[,(cols) :=lapply(.SD,get_gh),.SDcols = cols,by="Package"]
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
## These fields sometimes contain >1 link.
## Find the one that's actually for the GitHub repo.
if(is.null(db)) return (db)
get_gh <- function(col){
x <- stringr::str_split(col, ",")
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
}
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)][1]
db$url_github <- db[,list(sapply(git_url,get_gh),
sapply(URL,get_gh),
sapply(BugReports,get_gh))] |>
data.table::fcoalesce()
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)][1]
cols
cols <- cols[cols %in% names(db)]
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)]
cols
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
get_gh <- function(col){
x <- stringr::str_split(col, ",")
lapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
})
}
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
get_gh <- function(col){
x <- stringr::str_split(col, ",")
lapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
})
}
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
db$Packagedb
db
db$URL
db <- rworkflows::biocpkgtools_db
db[,lapply(.SD,get_gh),.SDcols = cols,by="Package"]
db[,lapply(.SD,get_gh),.SDcols = cols]
db[,lapply(.SD,get_gh),.SDcols = cols] |>   data.table::fcoalesce()
db[,lapply(.SD,get_gh),.SDcols = cols]
db[,sapply(.SD,get_gh),.SDcols = cols] |>
if(isTRUE(return_dt)){
return(db)
}else{
return(db$url_github)
}
get_gh <- function(col){
x <- stringr::str_split(col, ",")
sapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
})
}
db[,lapply(.SD,get_gh),.SDcols = cols] |>   data.table::fcoalesce()
db$url_github <- db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
db
db$url_github <- db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
db
sum(!is.na(db))
sum(!is.na(db$url_github))
db$url_github
devtools::document()
library(rworkflows)
testthat::expect_null(get_github_url_db(db = NULL))
source("~/Desktop/rworkflows/R/get_github_url_db.R", echo=TRUE)
testthat::expect_null(get_github_url_db(db = NULL))
db <- rworkflows::biocpkgtools_db
db$git_url <- NULL
testthat::expect_equal(
sum(!is.na(get_github_url_db(db = db))),
25
)
testthat::expect_equal(
sum(!is.na(get_github_url_db(db = db))),
39
)
db$git_url <- "https://someOtherURL.com"
db$url_github <- NULL
db$BugReports <- NULL
db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
db <- rworkflows::biocpkgtools_db
# db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
db$git_url <- "https://someOtherURL.com"
# db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
db$url_github <- NULL
# db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
db$BugReports <- NULL
test_that("get_github_url_db works", {
testthat::expect_null(get_github_url_db(db = NULL))
db <- rworkflows::biocpkgtools_db
db$git_url <- NULL
testthat::expect_equal(
sum(!is.na(get_github_url_db(db = db))),
39
)
db$git_url <- "https://someOtherURL.com"
db$url_github <- NULL
db$BugReports <- NULL
# db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
})
# db$URL <- NULL
sum(!is.na(get_github_url_db(db = db)))
db$git_url <- "https://someOtherURL.com"
db$url_github <- NULL
db$BugReports <- NULL
db$git_url <- NULL
testthat::expect_equal(
sum(!is.na(get_github_url_db(db = db))),
25
)
#### Prepare daa ####
db <- rworkflows::biocpkgtools_db
db$url_github <- NULL
usethis::use_test()
?use_workflow
devtools::check_man()
db <- rworkflows::biocpkgtools_db
get_gh <- function(col){
x <- strsplit(col, ",")
sapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
})
}
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)]
db$url_github <- db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
db
devtools::check_man()
devtools::check_man()
library(rworkflows)
use_workflow(template = "rworkflows_static",force_new = T, run_pkgdown = F)
install.packages("data.table")
install.packages("data.table")
library(rworkflows)
use_workflow(template = "rworkflows_static",force_new = T, run_pkgdown = F)
library(rworkflows)
use_workflow(template = "rworkflows_static",force_new = T, run_pkgdown = F)
library(rworkflows)
devtools::check_man()
library(rworkflows)
use_workflow(template = "rworkflows_static",force_new = T, run_pkgdown = F)
#### Gather remote data ####
d13c <- get_description(refs="ABSSeq",
db = NULL,
use_repos = TRUE)
refs="ABSSeq"
db = NULL
use_repos = TRUE
devoptera::args2vars(get_description)
refs="ABSSeq"
#### Method 2 ####
dl2 <- get_description_repo(refs = refs,
db = db,
verbose = verbose)
repo = c("BioCsoft",
"BioCann",
"BioCexp",
"BioCworkflows",
"CRAN")
#'  Can return a subset of results for specific packages as well.
#' @param db A \link[data.table]{data.table} of R package metadata generated by
#'  \link[BiocPkgTools]{biocPkgList}.
#' @inheritParams get_description
#' @inheritParams BiocPkgTools::biocPkgList
#' @returns Named list of \link[desc]{desc} objects.
#'
#' @keywords internal
#' @importFrom BiocManager version
#' @importFrom utils data
get_description_repo <- function(refs = NULL,
db = NULL,
repo = c("BioCsoft",
"BioCann",
"BioCexp",
"BioCworkflows",
"CRAN"),
version = BiocManager::version(),
verbose = TRUE){
# devoptera::args2vars(get_description_repo, reassign = TRUE)
force(refs)
messager("Searching for DESCRIPTION file(s) in R repositories:",
paste(repo,collapse = ", "),v=verbose)
#### Get package metadata across repositories ####
if(is.null(db)){
db <- get_description_repo_biocpkgtools(refs = refs,
repo = repo,
version = version,
verbose = verbose)
}
dt_to_desc(db = db,
refs = refs,
verbose = verbose)
# tools::CRAN_package_db()
# report <- BiocPkgTools::biocBuildReport()
# BiocPkgTools::githubDetails(pkgs = "bschilder/scKirby")
# dep_df = buildPkgDependencyDataFrame()
# g = buildPkgDependencyIgraph(dep_df)
# g2 = subgraphByDegree(g, "orthogene",degree = 1)
# library(visNetwork)
# data <- toVisNetworkData(g2)
# visNetwork(nodes = data$nodes, edges = data$edges, height = "500px") |>
#   visEdges(arrows='from')
# fields <- pkgsearch::cran_package(name = pkg)
# miniCRAN::addPackageListingGithub(repo = )
# deepdep::deepdep(package = "rworkflows",depth = 2,bioc = TRUE)
# d <- deepdep::get_description(package = "rworkflows")
# deepdep::plot_downloads("htmltools")
}
version = BiocManager::version()
force(refs)
messager("Searching for DESCRIPTION file(s) in R repositories:",
paste(repo,collapse = ", "),v=verbose)
#### Get package metadata across repositories ####
if(is.null(db)){
db <- get_description_repo_biocpkgtools(refs = refs,
repo = repo,
version = version,
verbose = verbose)
}
#### Use updated file ####
requireNamespace("BiocPkgTools")
tmp_dir <- file.path(tempdir(),"BiocPkgTools")
dir.create(tmp_dir,showWarnings = FALSE, recursive = TRUE)
tmp_dir <- file.path(tempdir(),"BiocPkgTools")
dir.create(tmp_dir,showWarnings = FALSE, recursive = TRUE)
#### Use updated file ####
tmp_dir <- file.path(tempdir(),"BiocPkgTools")
dir.create(tmp_dir,showWarnings = FALSE, recursive = TRUE)
#### Import each database ####
db <- lapply(stats::setNames(repo,repo), function(x){
messager("Importing database:",x,v=verbose)
#### Cache a local copy ####
tmp <- file.path(tmp_dir,paste0(x,".rds"))
if(file.exists(tmp) && isFALSE(force_new)){
db_i <- readRDS(tmp)
} else {
db_i <- BiocPkgTools::biocPkgList(repo=x,
version = version) |>
suppressMessages()
saveRDS(db_i, tmp)
}
return(db_i)
}) |> data.table::rbindlist(fill = TRUE,
use.names = TRUE,
idcol = "r_repo")
refs <- check_refs_names(dl = refs)
if(!is.null(refs)) db <- db[Package %in% basename(names(refs)),]
if(nrow(db)==0) {
messager("0 DESCRIPTION files found in CRAN/Bioc.",
"Returning NULL.",v=verbose)
return(NULL)
}
#### Parse GitHub URL #####
db <- get_github_url_db(db = db,
return_dt = TRUE)
# db <- rworkflows::biocpkgtools_db
## These fields sometimes contain >1 link.
## Find the one that's actually for the GitHub repo.
if(is.null(db)) return (db)
get_gh <- function(col){
x <- strsplit(col, ",")
sapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
})
}
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)]
db$url_github <- db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
cols
names(db)
db[,lapply(.SD,get_gh),.SDcols = cols]
db
db[,lapply(.SD,get_gh),.SDcols = cols, by="Package"]
db[,lapply(.SD,get_gh),.SDcols = cols]
db
db
db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
db[,lapply(.SD,get_gh),.SDcols = cols]
db[,lapply(.SD,get_gh),.SDcols = cols]|>str()
db[,lapply(.SD,get_gh),.SDcols = cols]$URL|>as.character()
is.na(db[,lapply(.SD,get_gh),.SDcols = cols]$URL|>as.character())
get_gh <- function(col){
x <- strsplit(col, ",")
sapply(x, function(x){
if(all(is.na(x))){
return(NA)
} else {
hits <- grep(".*http[s]?://github.com/(([^/]+)/([^/]+)).*", x,
value = TRUE)[1]
if(length(hits)==0) {
return(NA)
} else{
hits |>
gsub(pattern="/issues$",replacement="") |>
trimws() |>
trimws(whitespace="\n")
}
}
}) |> as.character()
}
#### Parse ####
cols <- c("git_url","URL","BugReports")
cols <- cols[cols %in% names(db)]
db$url_github <- db[,lapply(.SD,get_gh),.SDcols = cols] |>
data.table::fcoalesce()
library(rworkflows)
#### Run first time ####
d13a <- get_description(refs="ABSSeq",
db = rworkflows::biocpkgtools_db,
use_repos = TRUE)
testthat::expect_equal(d13a[[1]],
d1[[1]])
#### Rerun to use stored DESCRITPION files ####
d13b <- get_description(refs="ABSSeq",
db = rworkflows::biocpkgtools_db,
use_repos = TRUE)
testthat::expect_equal(d13b[[1]],
d1[[1]])
#### Unable to find pkg info ####
testthat::expect_null(
get_description(refs="typooo",
db = rworkflows::biocpkgtools_db,
use_repos = TRUE)
)
#### Gather remote data ####
d13c <- get_description(refs="ABSSeq",
db = NULL,
use_repos = TRUE)
devtools::install_github("Bioconductor/BiocStyle")
BiocCheck::BiocCheck()
BiocManager::repositories()
